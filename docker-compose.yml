data:
    image: busybox
    command: "true"
    volumes:
        - /docs
        - /public

fetch:
    image: docsdockercom:latest
    command: |
        /bin/bash -ec " \
        python fetch_content.py /docs all-projects.yml
        ./touch-up.sh /docs
        "
    volumes_from:
        - data
    environment:
        - GITHUB_USERNAME
        - GITHUB_TOKEN

build:
    image: docsdockercom:latest
    command: /bin/bash -ec "hugo -d /public/$DOCS_VERSION"
    working_dir: /docs
    volumes_from:
        - data
    environment:
        - DOCS_VERSION

upload:
    image: docsdockercom:latest
    working_dir: /public
    command: |
        /bin/bash -c ' \
        if [ -n "$CLEAN" ] ; then
          aws s3 rm --recursive s3://$AWS_S3_BUCKET/$CLEAN
        fi
        aws s3 sync --acl=public-read . s3://$AWS_S3_BUCKET
        '
    volumes_from:
        - data
    environment:
        - CLEAN
        - AWS_ACCESS_KEY_ID
        - AWS_SECRET_ACCESS_KEY
        - AWS_S3_BUCKET

cleanup:
    image: docsdockercom:latest
    command: |
        /bin/bash -c ' \
        if [[ "$AWS_S3_BUCKET" =~ "/" ]] ; then
            BUCKET_PATH=$( echo "$AWS_S3_BUCKET" | sed "s/[^\/]*\///" )
            BUCKET_PATH+="/"
            AWS_S3_BUCKET=$( echo "$AWS_S3_BUCKET" | sed "s/\/.*//")
        else
            BUCKET_PATH=
        fi

        [ -z "$RM_OLDER_THAN" ] && exit 1
        CUTOFF_UNIX_TS=$( date --date "$RM_OLDER_THAN" '+%s' )
        aws s3 ls --recursive s3://$AWS_S3_BUCKET/$BUCKET_PATH | while read -a LINE ; do
            DATE="${LINE[0]}"
            TIME="${LINE[1]}"
            SIZE="${LINE[2]}"
            NAME="${LINE[*]:3}"

            VERSION_REGEX="^${BUCKET_PATH}v[0-9]+\.[0-9]+/"
            UNIX_TS=$( date --date "$DATE $TIME" "+%s" )

            if [[ "$NAME" =~ $VERSION_REGEX ]] || [[ "$CUTOFF_UNIX_TS" -le "$UNIX_TS" ]] ; then
                echo "Keeping $NAME"
                continue
            fi

            echo "Creating redirect for $NAME"
            aws s3 cp "s3://$AWS_S3_BUCKET/$NAME" "s3://$AWS_S3_BUCKET/$NAME" --website-redirect="/${BUCKET_PATH}index.html" --acl=public-read > /dev/null
        done
        '
    environment:
        - RM_OLDER_THAN
        - AWS_ACCESS_KEY_ID
        - AWS_SECRET_ACCESS_KEY
        - AWS_S3_BUCKET

serve:
    image: docsdockercom:latest
    working_dir: /docs
    command: /bin/bash -c "hugo server -d /public --port=8000 --baseUrl=$HUGO_BASE_URL --bind=$HUGO_BIND_IP"
    environment:
        - HUGO_BASE_URL
        - HUGO_BIND_IP
    ports:
        - "8000:8000"
    volumes_from:
        - data

test:
    image: docsdockercom:latest
    working_dir: /docs
    command: |
        /bin/bash -c " \
        URL=http://$HUGO_BASE_URL:8000
        hugo server -d /public --port=8000 --baseUrl=$HUGO_BASE_URL --bind=$HUGO_BIND_IP &
        until curl --fail --silent $URL ; do \
          sleep 1 ; \
        done
        exec python /src/docvalidate.py $URL
        "
    environment:
        - HUGO_BASE_URL
        - HUGO_BIND_IP
    ports:
        - "8000:8000"
    volumes_from:
        - data
